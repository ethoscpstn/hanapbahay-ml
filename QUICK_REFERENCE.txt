═══════════════════════════════════════════════════════════════
   HANAPBAHAY ML SERVICE - QUICK REFERENCE CARD
═══════════════════════════════════════════════════════════════

╔══════════════════════════════════════════════════════════════╗
║  DAILY USAGE - START ML SERVICE                              ║
╚══════════════════════════════════════════════════════════════╝

1. Open "Anaconda Prompt"
2. Run these commands:

   conda activate hanapbahay
   cd c:\xampp\htdocs\public_html\ml_service
   python app.py

3. Keep this window open!
4. You should see: "Uvicorn running on http://127.0.0.1:8000"

═══════════════════════════════════════════════════════════════

╔══════════════════════════════════════════════════════════════╗
║  STOP ML SERVICE                                             ║
╚══════════════════════════════════════════════════════════════╝

Press Ctrl+C in the Anaconda Prompt window

═══════════════════════════════════════════════════════════════

╔══════════════════════════════════════════════════════════════╗
║  TEST IF SERVICE IS WORKING                                  ║
╚══════════════════════════════════════════════════════════════╝

Open regular Command Prompt (NEW window):

   curl http://localhost:8000/version

If you get JSON response → IT'S WORKING! ✓

Or run:
   cd c:\xampp\htdocs\public_html\ml_service
   test_service.bat

═══════════════════════════════════════════════════════════════

╔══════════════════════════════════════════════════════════════╗
║  CHECK MODEL INFORMATION                                     ║
╚══════════════════════════════════════════════════════════════╝

In Anaconda Prompt:

   conda activate hanapbahay
   cd c:\xampp\htdocs\public_html\ml_service
   python check_model_info.py

═══════════════════════════════════════════════════════════════

╔══════════════════════════════════════════════════════════════╗
║  TROUBLESHOOTING                                             ║
╚══════════════════════════════════════════════════════════════╝

Problem: "Port 8000 already in use"
Solution:
   netstat -ano | findstr :8000
   taskkill /PID <number> /F

Problem: Service won't start
Solution:
   1. Check model files exist: dir artifacts
   2. Run: verify_setup.bat

Problem: PHP can't connect
Solution:
   1. Make sure ML service is running
   2. Make sure XAMPP Apache is running
   3. Check config.php has: ML_BASE = http://127.0.0.1:8000

═══════════════════════════════════════════════════════════════

╔══════════════════════════════════════════════════════════════╗
║  UPDATE MODEL FROM COLAB                                     ║
╚══════════════════════════════════════════════════════════════╝

1. In Colab: Run all cells + download artifacts
2. Stop ML service (Ctrl+C)
3. Backup old model:
   mkdir artifacts\backup
   copy artifacts\*.* artifacts\backup\

4. Copy new model_latest.joblib and meta.json to artifacts\
5. Restart: python app.py

═══════════════════════════════════════════════════════════════

╔══════════════════════════════════════════════════════════════╗
║  IMPORTANT FILES                                             ║
╚══════════════════════════════════════════════════════════════╝

app.py                    → Main ML service
artifacts/                → Model files folder
  ├─ model_latest.joblib  → Trained model
  └─ meta.json            → Model metadata

start_service_conda.bat   → Quick start script
test_service.bat          → Test all endpoints
verify_setup.bat          → Check installation
check_model_info.py       → Show model info

COMMANDS_GUIDE.md         → Full documentation (this file!)

═══════════════════════════════════════════════════════════════

╔══════════════════════════════════════════════════════════════╗
║  TYPICAL WORKFLOW                                            ║
╚══════════════════════════════════════════════════════════════╝

Morning/Start Work:
  1. Open Anaconda Prompt
  2. conda activate hanapbahay
  3. cd c:\xampp\htdocs\public_html\ml_service
  4. python app.py
  5. Start XAMPP → Apache

  → ML predictions now work on your website!

End of Day:
  1. Ctrl+C in Anaconda Prompt
  2. Stop Apache in XAMPP

═══════════════════════════════════════════════════════════════

💡 TIP: Pin this file or print it for quick reference!

═══════════════════════════════════════════════════════════════
